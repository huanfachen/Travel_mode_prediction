{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import cluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# imbalanced learning\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn import under_sampling, over_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw data and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lpmc = pd.read_csv(\"20200721 lpmc.csv\", header=0,sep=',')\n",
    "\n",
    "\n",
    "# Creating new variables\n",
    "lpmc['dur_pt_inv'] = lpmc['dur_pt_rail'] + lpmc['dur_pt_bus']\n",
    "lpmc['cost_driving_total'] = lpmc['cost_driving_fuel'] + lpmc['cost_driving_ccharge']\n",
    "lpmc['male'] = 1-lpmc['female']\n",
    "lpmc['dur_pt_int_total'] = lpmc['dur_pt_int']\n",
    "lpmc['pt_n_interchanges'] = lpmc['pt_interchanges']\n",
    "\n",
    "X = lpmc.drop(columns=['travel_mode'])\n",
    "y = lpmc['travel_mode']\n",
    "\n",
    "# Spliting training and testig sets \n",
    "# Rule 3: Survey-year based splitting with 1st and 2nd year as training and 3rd year as testing sets\n",
    "\n",
    "X_train = lpmc[lpmc['survey_year']<=2].drop(columns=['travel_mode'])\n",
    "y_train = lpmc[lpmc['survey_year']<=2]['travel_mode']\n",
    "X_test = lpmc[lpmc['survey_year']==3].drop(columns=['travel_mode'])\n",
    "y_test = lpmc[lpmc['survey_year']==3]['travel_mode']\n",
    "\n",
    "# Output\n",
    "# print('X_train')\n",
    "# print(X_train)\n",
    "# print('y_train') \n",
    "# print(y_train)    \n",
    "# print('X_test')\n",
    "# print(X_test)\n",
    "# print('y_test') \n",
    "# print(y_test)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating new variables and extract variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables\n",
    "\n",
    "Identifiers = ['trip_id','household_id','person_n','trip_n']\n",
    "\n",
    "Variables = ['age','male','driving_license','car_ownership','distance',\\\n",
    "             'dur_walking','dur_cycling', 'dur_pt_access','dur_pt_inv','dur_pt_int_total','pt_n_interchanges','dur_driving',\\\n",
    "             'cost_transit','cost_driving_total']\n",
    "\n",
    "Identifiers.extend(Variables)\n",
    "# print(Identifiers)\n",
    "\n",
    "X_train= X_train[Identifiers]\n",
    "X_test= X_test[Identifiers]\n",
    "\n",
    "list_categorical_var = ['male','driving_license','car_ownership', 'pt_n_interchanges']\n",
    "mask_cateogrical_var = [e in list_categorical_var for e in X_train.columns]\n",
    "# print(mask_cateogrical_var)\n",
    "\n",
    "# Output\n",
    "# print('X_train')\n",
    "# print(X_train)\n",
    "# print('y_train') \n",
    "# print(y_train)    \n",
    "# print('X_test')\n",
    "# print(X_test)\n",
    "# print('y_test') \n",
    "# print(y_test)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Under-sampling<br/>\n",
    "    1.1 Random majority under-sampling with replacement<br/>\n",
    "    1.2 One-Sided Selection<br/>\n",
    "    1.3 Neighboorhood Cleaning Rule <br/>\n",
    "    1.4 Under-sampling with Cluster Centroids<br/>\n",
    "2. Over-sampling<br/>\n",
    "    2.1 Random minority over-sampling with replacement<br/>\n",
    "    2.2 SMOTENC - SMOTE for Nominal and Continuous <br/>\n",
    "    2.3 ADASYN - Adaptive synthetic sampling approach for imbalanced learning<br/>\n",
    "3. Over-sampling followed by under-sampling<br/>\n",
    "    SMOTE + Tomek links <br/>\n",
    "    SMOTE + ENN <br/><br/>\n",
    "4. Ensemble classifier using samplers internally\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the resampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling_method:1.1\n",
      "Random_state:200\n",
      "1.1_RandomUnderSampler starts.\n",
      "Dataset written.\n",
      "Random_state:400\n",
      "1.1_RandomUnderSampler starts.\n",
      "Dataset written.\n",
      "Random_state:600\n",
      "1.1_RandomUnderSampler starts.\n",
      "Dataset written.\n",
      "Random_state:800\n",
      "1.1_RandomUnderSampler starts.\n",
      "Dataset written.\n",
      "Random_state:1000\n",
      "1.1_RandomUnderSampler starts.\n",
      "Dataset written.\n",
      "Random_state:1200\n",
      "1.1_RandomUnderSampler starts.\n",
      "Dataset written.\n",
      "Random_state:1400\n",
      "1.1_RandomUnderSampler starts.\n",
      "Dataset written.\n",
      "Random_state:1600\n",
      "1.1_RandomUnderSampler starts.\n",
      "Dataset written.\n",
      "Random_state:1800\n",
      "1.1_RandomUnderSampler starts.\n",
      "Dataset written.\n",
      "Random_state:2000\n",
      "1.1_RandomUnderSampler starts.\n",
      "Dataset written.\n",
      "Processing time:\n",
      "   1.1_RandomUnderSampler\n",
      "0                0.030881\n",
      "1                0.021941\n",
      "2                0.028925\n",
      "3                0.019947\n",
      "4                0.024937\n",
      "5                0.020914\n",
      "6                0.026021\n",
      "7                0.022979\n",
      "8                0.025251\n",
      "9                0.019162\n",
      "Writing to Excel Finished.\n",
      "Resampling_method:1.2\n",
      "Random_state:200\n",
      "1.2_One-SidedSelection starts.\n",
      "Dataset written.\n",
      "Random_state:400\n",
      "1.2_One-SidedSelection starts.\n",
      "Dataset written.\n",
      "Random_state:600\n",
      "1.2_One-SidedSelection starts.\n",
      "Dataset written.\n",
      "Random_state:800\n",
      "1.2_One-SidedSelection starts.\n",
      "Dataset written.\n",
      "Random_state:1000\n",
      "1.2_One-SidedSelection starts.\n",
      "Dataset written.\n",
      "Random_state:1200\n",
      "1.2_One-SidedSelection starts.\n",
      "Dataset written.\n",
      "Random_state:1400\n",
      "1.2_One-SidedSelection starts.\n",
      "Dataset written.\n",
      "Random_state:1600\n",
      "1.2_One-SidedSelection starts.\n",
      "Dataset written.\n",
      "Random_state:1800\n",
      "1.2_One-SidedSelection starts.\n",
      "Dataset written.\n",
      "Random_state:2000\n",
      "1.2_One-SidedSelection starts.\n",
      "Dataset written.\n",
      "Processing time:\n",
      "   1.2_One-SidedSelection\n",
      "0               20.856830\n",
      "1               20.050810\n",
      "2               20.293160\n",
      "3               20.130757\n",
      "4               20.526270\n",
      "5               20.446736\n",
      "6               20.329163\n",
      "7               20.560176\n",
      "8               19.532064\n",
      "9               19.915737\n",
      "Writing to Excel Finished.\n",
      "Resampling_method:1.3\n",
      "Random_state:200\n",
      "1.3_NeighbourhoodCleaningRule starts.\n",
      "Dataset written.\n",
      "Random_state:400\n",
      "1.3_NeighbourhoodCleaningRule starts.\n",
      "Dataset written.\n",
      "Random_state:600\n",
      "1.3_NeighbourhoodCleaningRule starts.\n",
      "Dataset written.\n",
      "Random_state:800\n",
      "1.3_NeighbourhoodCleaningRule starts.\n",
      "Dataset written.\n",
      "Random_state:1000\n",
      "1.3_NeighbourhoodCleaningRule starts.\n",
      "Dataset written.\n",
      "Random_state:1200\n",
      "1.3_NeighbourhoodCleaningRule starts.\n",
      "Dataset written.\n",
      "Random_state:1400\n",
      "1.3_NeighbourhoodCleaningRule starts.\n",
      "Dataset written.\n",
      "Random_state:1600\n",
      "1.3_NeighbourhoodCleaningRule starts.\n",
      "Dataset written.\n",
      "Random_state:1800\n",
      "1.3_NeighbourhoodCleaningRule starts.\n",
      "Dataset written.\n",
      "Random_state:2000\n",
      "1.3_NeighbourhoodCleaningRule starts.\n",
      "Dataset written.\n",
      "Processing time:\n",
      "   1.3_NeighbourhoodCleaningRule\n",
      "0                     100.993450\n",
      "1                      99.266290\n",
      "2                     101.612349\n",
      "3                     109.009439\n",
      "4                     101.395248\n",
      "5                     100.587623\n",
      "6                     100.417791\n",
      "7                     102.596632\n",
      "8                     120.401333\n",
      "9                     109.487697\n",
      "Writing to Excel Finished.\n",
      "Resampling_method:2.1\n",
      "Random_state:200\n",
      "2.1_RandomOverSampler starts.\n",
      "Dataset written.\n",
      "Random_state:400\n",
      "2.1_RandomOverSampler starts.\n",
      "Dataset written.\n",
      "Random_state:600\n",
      "2.1_RandomOverSampler starts.\n",
      "Dataset written.\n",
      "Random_state:800\n",
      "2.1_RandomOverSampler starts.\n",
      "Dataset written.\n",
      "Random_state:1000\n",
      "2.1_RandomOverSampler starts.\n",
      "Dataset written.\n",
      "Random_state:1200\n",
      "2.1_RandomOverSampler starts.\n",
      "Dataset written.\n",
      "Random_state:1400\n",
      "2.1_RandomOverSampler starts.\n",
      "Dataset written.\n",
      "Random_state:1600\n",
      "2.1_RandomOverSampler starts.\n",
      "Dataset written.\n",
      "Random_state:1800\n",
      "2.1_RandomOverSampler starts.\n",
      "Dataset written.\n",
      "Random_state:2000\n",
      "2.1_RandomOverSampler starts.\n",
      "Dataset written.\n",
      "Processing time:\n",
      "   2.1_RandomOverSampler\n",
      "0               0.066855\n",
      "1               0.101730\n",
      "2               0.068815\n",
      "3               0.069813\n",
      "4               0.072852\n",
      "5               0.064984\n",
      "6               0.095525\n",
      "7               0.085249\n",
      "8               0.063811\n",
      "9               0.068847\n",
      "Writing to Excel Finished.\n",
      "Resampling_method:2.2\n",
      "Random_state:200\n",
      "2.2_SMOTENC starts.\n",
      "Dataset written.\n",
      "Random_state:400\n",
      "2.2_SMOTENC starts.\n",
      "Dataset written.\n",
      "Random_state:600\n",
      "2.2_SMOTENC starts.\n",
      "Dataset written.\n",
      "Random_state:800\n",
      "2.2_SMOTENC starts.\n",
      "Dataset written.\n",
      "Random_state:1000\n",
      "2.2_SMOTENC starts.\n",
      "Dataset written.\n",
      "Random_state:1200\n",
      "2.2_SMOTENC starts.\n",
      "Dataset written.\n",
      "Random_state:1400\n",
      "2.2_SMOTENC starts.\n",
      "Dataset written.\n",
      "Random_state:1600\n",
      "2.2_SMOTENC starts.\n",
      "Dataset written.\n",
      "Random_state:1800\n",
      "2.2_SMOTENC starts.\n",
      "Dataset written.\n",
      "Random_state:2000\n",
      "2.2_SMOTENC starts.\n",
      "Dataset written.\n",
      "Processing time:\n",
      "   2.2_SMOTENC\n",
      "0    29.784150\n",
      "1    27.005276\n",
      "2    25.853680\n",
      "3    24.839573\n",
      "4    25.601865\n",
      "5    24.538896\n",
      "6    24.092539\n",
      "7    26.896719\n",
      "8    24.368151\n",
      "9    27.213209\n",
      "Writing to Excel Finished.\n",
      "Resampling_method:2.3\n",
      "Random_state:200\n",
      "2.3_ADASYN starts.\n",
      "Dataset written.\n",
      "Random_state:400\n",
      "2.3_ADASYN starts.\n",
      "Dataset written.\n",
      "Random_state:600\n",
      "2.3_ADASYN starts.\n",
      "Dataset written.\n",
      "Random_state:800\n",
      "2.3_ADASYN starts.\n",
      "Dataset written.\n",
      "Random_state:1000\n",
      "2.3_ADASYN starts.\n",
      "Dataset written.\n",
      "Random_state:1200\n",
      "2.3_ADASYN starts.\n",
      "Dataset written.\n",
      "Random_state:1400\n",
      "2.3_ADASYN starts.\n",
      "Dataset written.\n",
      "Random_state:1600\n",
      "2.3_ADASYN starts.\n",
      "Dataset written.\n",
      "Random_state:1800\n",
      "2.3_ADASYN starts.\n",
      "Dataset written.\n",
      "Random_state:2000\n",
      "2.3_ADASYN starts.\n",
      "Dataset written.\n",
      "Processing time:\n",
      "   2.3_ADASYN\n",
      "0   81.504584\n",
      "1   76.591768\n",
      "2   70.455774\n",
      "3   70.240398\n",
      "4   71.043091\n",
      "5   72.616163\n",
      "6   69.783025\n",
      "7   69.966630\n",
      "8   71.398376\n",
      "9   72.950110\n",
      "Writing to Excel Finished.\n"
     ]
    }
   ],
   "source": [
    "methodrange = [1.1,1.2,1.3,2.1,2.2,2.3]\n",
    "\n",
    "# Iteration for resampling method\n",
    "for i in range(6): \n",
    "    resampling_method = methodrange[i]\n",
    "    print(\"Resampling_method:\" + str(resampling_method))\n",
    "    random_seed_resample = 0\n",
    "    proc_time_list = []\n",
    "    \n",
    "    # Iteration for generating 10 files for each resampling method\n",
    "    for j in range(10): \n",
    "        random_seed_resample = random_seed_resample + 200\n",
    "        # random_seed_resample = 1009\n",
    "        print(\"Random_state:\" + str(random_seed_resample))\n",
    "        \n",
    "        # Resampling\n",
    "        if resampling_method == 1.1: # Random majority under-sampling with replacement\n",
    "                resmplnm = '1.1_RandomUnderSampler'\n",
    "                resmpl = under_sampling.RandomUnderSampler(random_state=random_seed_resample)\n",
    "        elif resampling_method == 1.2:# One-Sided Selection\n",
    "                resmplnm = '1.2_One-SidedSelection'\n",
    "                resmpl = under_sampling.OneSidedSelection(random_state=random_seed_resample,n_neighbors=3, n_seeds_S=1000, n_jobs=-1)\n",
    "        elif resampling_method == 1.3:# Neighboorhood Cleaning Rule\n",
    "                resmplnm = '1.3_NeighbourhoodCleaningRule'\n",
    "                resmpl = under_sampling.NeighbourhoodCleaningRule (n_jobs=-1)\n",
    "        elif resampling_method == 2.1:# Random minority over-sampling with replacement\n",
    "                resmplnm = '2.1_RandomOverSampler'\n",
    "                resmpl = over_sampling.RandomOverSampler(random_state=random_seed_resample)\n",
    "        elif resampling_method == 2.2:# SMOTENC - SMOTE for Nominal and Continuous\n",
    "                resmplnm = '2.2_SMOTENC'\n",
    "                resmpl = over_sampling.SMOTENC(random_state=random_seed_resample, categorical_features=mask_cateogrical_var,n_jobs=-1)\n",
    "        elif resampling_method == 2.3:# ADASYN - Adaptive synthetic sampling approach for imbalanced learning\n",
    "                resmplnm = '2.3_ADASYN'\n",
    "                resmpl = over_sampling.ADASYN(random_state=random_seed_resample,n_jobs=-1)\n",
    "\n",
    "        print(resmplnm + \" starts.\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        X_train_resampled, y_train_resampled = resmpl.fit_resample(X_train, y_train)\n",
    "        y_train_resampled = y_train_resampled.replace([1, 2, 3, 4], ['walk', 'cycle', 'pt', 'drive'])\n",
    "                \n",
    "    \n",
    "        end_time = time.time()\n",
    "        proc_time = end_time - start_time \n",
    "        proc_time_list.append(proc_time)\n",
    " \n",
    "               \n",
    "        # Write x_train into csv files\n",
    "        bookname1 = resmplnm + '_' + str(j+1) + '_X_Train.csv'\n",
    "        X_train_resampled.to_csv(bookname1, index=False)\n",
    "        bookname2 = resmplnm + '_' + str(j+1) + '_Y_Train.csv'\n",
    "        y_train_resampled.to_csv(bookname2, index=False)\n",
    "        \n",
    "        print(\"Dataset written.\")\n",
    "       \n",
    "\n",
    "    \n",
    "    proc_time_df=pd.DataFrame(proc_time_list,columns=[resmplnm])\n",
    "    print(\"Processing time:\")\n",
    "    print(proc_time_df)\n",
    "    \n",
    "    # Write Processing time into Excel spreadsheet\n",
    "    book = load_workbook('20210428 Resampling time.xlsx')\n",
    "    writer = pd.ExcelWriter('20210428 Resampling time.xlsx', engine='openpyxl') \n",
    "    writer.book = book\n",
    "\n",
    "    ## ExcelWriter for some reason uses writer.sheets to access the sheet.\n",
    "    ## If you leave it empty it will not know that sheet Main is already there\n",
    "    ## and will create a new sheet.\n",
    "\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "    proc_time_df.to_excel(writer, sheet_name = \"Processing time\", startcol = 1+i,index = False)\n",
    "\n",
    "    writer.save()\n",
    "\n",
    "    print(\"Writing to Excel Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.replace([1, 2, 3, 4], ['walk', 'cycle', 'pt', 'drive'])\n",
    "y_test = y_test.replace([1, 2, 3, 4], ['walk', 'cycle', 'pt', 'drive'])\n",
    "                \n",
    "bookname1 = 'Original_X_Train.csv'\n",
    "X_train.to_csv(bookname1, index=False)\n",
    "bookname2 = 'Original_Y_Train.csv'\n",
    "y_train.to_csv(bookname2, index=False)\n",
    "bookname3 = 'Original_X_Test.csv'\n",
    "X_test.to_csv(bookname3, index=False)\n",
    "bookname4 = 'Original_Y_Test.csv'\n",
    "y_test.to_csv(bookname4, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resampling_method = 1.4\n",
    "random_seed_resample = 0\n",
    "\n",
    "for j in range(10): \n",
    "    random_seed_resample = random_seed_resample + 200\n",
    "    print(\"Random_state:\" + str(random_seed_resample))\n",
    "\n",
    "    if resampling_method == 1.2:# Condensed Nearest Neighbour\n",
    "            resmplnm = '1.2 CondensedNearestNeighbour'\n",
    "            resmpl = under_sampling.CondensedNearestNeighbour(random_state=random_seed_resample, n_neighbors=3, n_seeds_S=20000, n_jobs=-1)\n",
    "    elif resampling_method == 1.3:# Instance Hardness Threshold\n",
    "            resmplnm = '1.3 InstanceHardnessThreshold'\n",
    "            resmpl = under_sampling.InstanceHardnessThreshold(random_state=random_seed_resample, n_jobs=-1)\n",
    "    elif resampling_method == 2.3:# ADASYN - Adaptive synthetic sampling approach for imbalanced learning\n",
    "            resmplnm = '2.3_ADASYN'\n",
    "            resmpl = over_sampling.ADASYN(random_state=random_seed_resample,n_jobs=-1)\n",
    "#             resmpl = over_sampling.ADASYN(random_state=random_seed_resample,sampling_strategy='minority',n_jobs=-1)\n",
    "    elif resampling_method == 1.4:# Under-sampling with Cluster Centroids/Medoids\n",
    "                resmplnm = '1.4_ClusterCentroids'\n",
    "                resmpl = under_sampling.ClusterCentroids(random_state=random_seed_resample,estimator = cluster.DBSCAN(eps=3, min_samples=2)) # change estimator = cluster.DBSCAN\n",
    "   \n",
    "    print(resmplnm + \" starts.\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = resmpl.fit_resample(X_train, y_train)\n",
    "#     X_test_resampled, y_test_resampled = resmpl.fit_resample(X_test, y_test)\n",
    "    y_train_resampled = y_train_resampled.replace([1, 2, 3, 4], ['walk', 'cycle', 'pt', 'drive'])\n",
    "#     y_test_resampled = y_test_resampled.replace([1, 2, 3, 4], ['walk', 'cycle', 'pt', 'drive'])\n",
    "#         print (y_train_resampled)\n",
    "#         print (y_test_resampled)\n",
    "\n",
    "    end_time = time.time()\n",
    "    proc_time = end_time - start_time \n",
    "    proc_time_list.append(proc_time)\n",
    "    # print (X_train_resampled.describe())\n",
    "\n",
    "    # Write x_train into csv files\n",
    "    bookname1 = resmplnm + '_X_Train_'+ str(j+1) +'.csv'\n",
    "    X_train_resampled.to_csv(bookname1, index=False)\n",
    "    bookname2 = resmplnm + '_Y_Train_'+ str(j+1) +'.csv'\n",
    "    y_train_resampled.to_csv(bookname2, index=False)\n",
    "#     bookname3 = resmplnm + '_X_Test_'+ str(j+1) +'.csv'\n",
    "#     X_test_resampled.to_csv(bookname3, index=False)\n",
    "#     bookname4 = resmplnm + '_Y_Test_'+ str(j+1) +'.csv'\n",
    "#     y_test_resampled.to_csv(bookname4, index=False)\n",
    "\n",
    "    print(\"Dataset written.\")\n",
    "      \n",
    "proc_time_df = pd.DataFrame(proc_time_list,columns=[resmplnm])\n",
    "print(\"Processing time:\")\n",
    "print(proc_time_df)\n",
    "    \n",
    "# Write Processing into Excel spreadsheet\n",
    "book = load_workbook('20210428 Resampling time.xlsx')\n",
    "writer = pd.ExcelWriter('20210428 Resampling time.xlsx', engine='openpyxl') \n",
    "writer.book = book\n",
    "\n",
    "## ExcelWriter for some reason uses writer.sheets to access the sheet.\n",
    "## If you leave it empty it will not know that sheet Main is already there\n",
    "## and will create a new sheet.\n",
    "\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "proc_time_df.to_excel(writer, sheet_name = \"Processing time\", startcol = 8,index = False)\n",
    "\n",
    "writer.save()\n",
    "\n",
    "print(\"Writing to Excel Finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
